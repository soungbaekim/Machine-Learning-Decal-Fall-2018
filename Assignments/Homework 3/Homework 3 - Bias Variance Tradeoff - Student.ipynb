{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy.stats import randint\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Tradeoff\n",
    "\n",
    "This notebook will walk through one of the most fundamental concepts in machine learning, the bias variance tradeoff, by letting you experiment with various settings of hyperparameters for decision trees and SVMs. \n",
    "\n",
    "Note: In this homework, you will be seeing types of ML models (eg: decision trees) that we haven't covered in lecture. We hope that through this homework, you will see how each model has various hyper parameters that can be tuned to determine how much the model fits to the training data set, rather than focusing on how exactly the models work. Here are lecture slides from previous offerings of the class that go over decision trees and SVMs in more detail if you are interested:\n",
    "    * Decision Trees: https://github.com/mlberkeley/Machine-Learning-Decal-Spring-2018/blob/master/Lecture%205/lecture5.pdf\n",
    "    * SVMS: https://github.com/mlberkeley/Machine-Learning-Decal-Spring-2018/blob/master/Lecture%206/Lecture%206%20Slides.pdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Decision Trees\n",
    "\n",
    "A decision tree is a model with a tree structure, that has a collection of if, then statements in its internal nodes. A new data point is routed through the tree based on the answer to the if, then statements until it reaches a leaf node, which represents the class. \n",
    "\n",
    "<img src=\"decision_tree.png\">\n",
    "\n",
    "To learn the features and values to split on, we greedily find the feature and value that best splits the data in the parent, so the child nodes can have more homogenous class values. This is formally known as minimizing entropy.\n",
    "\n",
    "If left unconstrained, a decision tree can form as many layers as required to perfectly memorize the training dataset (eg: have exactly one training example in each leaf node). This results in a high variance model. To improve the generalization ability of decision trees, we can use various heuristics to limit the expressive capacity of the tree. Some examples are:\n",
    "* Early stopping - limit the depth of the tree, or the threshold the purity of the classes of the leaves; limiting the depth of the tree, requiring a minimum number of samples per leaf, and setting the max number of nodes per leaf all prevent the tree from growing fully and reduce the variance\n",
    "* Pruning - create the full tree and greedily remove trees to improve validation accuracy\n",
    "\n",
    "We will now play around with various hyperparameters of decision trees using the Iris Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the iris dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then add the species label to each datapoint using the encoding given in the dataset to understand what the overall dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataframe into training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "train = train.drop(['is_train'], axis = 1)\n",
    "test = test.drop(['is_train'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the labels and feature from both the training and test datasets and refactorize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train[train.columns[:4]]\n",
    "train_labels = pd.factorize(train['species'])[0]\n",
    "test_features = test[test.columns[:4]]\n",
    "test_labels = pd.factorize(test['species'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a basic decision tree which minimizes entropy and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the training and validation accuracies. You should notice the decision tree gets a higher training accuracy than validation. Decision trees have the capability to fit each training point accurately, so if left unregulated the tree will probably end up overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use Grid Search to find a good set of hyperparameters which attempt to regualize the tree. Grid search allows us to pick the combination of hyperparameters that results in the best model. Feel free to play around with the parameters of grid search to find a better tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"min_samples_split\": [2, 10],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "              }\n",
    "gridsearch = GridSearchCV(clf, parameters)\n",
    "gridsearch.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = gridsearch.best_estimator_ \n",
    "best_tree.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Report the values of the hyperparameters that produced the best tree. Where do the final hyperparameters fall in the range that you tested? Why is this so? What is the tradeoff between regularizing the model and increasing its training accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the training and validation accuracies. On a dataset like Iris, the unregularized decision tree may already achieve the highest validation accuracy, but this method of regularization is useful when using decision trees for more complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "We will now use the SVM implementation in sklearn to classify 2D datasets and understand how to tune the hyperparameters of SVMS. This part of the notebook is adapted from http://nbviewer.jupyter.org/github/jdwittenauer/ipython-notebooks/blob/master/notebooks/ml/ML-Exercise6.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to Choose C\n",
    "Large C:\n",
    "* Goal is to misclassify few training points\n",
    "* Often results in small margins\n",
    "* Very sensitive to outliers\n",
    "* Risk of overfitting\n",
    "\n",
    "Small C:\n",
    "* Maximizes margin at cost of misclassifying training data points\n",
    "* Risk of underfitting\n",
    "\n",
    "We will now look at a nonlinear dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadmat('ex6data2.mat')\n",
    "\n",
    "data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])\n",
    "data['y'] = raw_data['y']\n",
    "\n",
    "positive = data[data['y'].isin([1])]\n",
    "negative = data[data['y'].isin([0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')\n",
    "ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data set we'll build a support vector machine classifier using the built-in RBF kernel and examine its accuracy on the training data. To visualize the decision boundary, this time we'll shade the points based on the predicted probability that the instance has a negative class label. We'll see from the result that it gets most of them right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(C=100, gamma=10, probability=True)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(data[['X1', 'X2']], data['y'])\n",
    "svc.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Probability'] = svc.predict_proba(data[['X1', 'X2']])[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fill in the following function to use grid search to find the optimal value of C and gamma (hyperparameter of the RBF kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    # Fill in the dots\n",
    "    Cs = [...]\n",
    "    gammas = [...]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    search = grid_search.GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    search.fit(X, y)\n",
    "    search.best_params_\n",
    "    return search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_selection(data[['X1', 'X2']], data['y'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Based on how you chose potential values to search over, how do you know you found a good value of C and gamma?\n",
    "\n",
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use your optimal values of C and gamma to train the SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your optimal values of C and gamma; You should achieve a higher accuracy than before\n",
    "svc = svm.SVC(C=..., gamma=..., probability=True)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(data[['X1', 'X2']], data['y'])\n",
    "svc.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Probability'] = svc.predict_proba(data[['X1', 'X2']])[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: For a fixed value of C, modify the value of gamma and see how the model predicts on the training set. Do higher or lower values of gamma correspond to a high variance model?\n",
    "\n",
    "For more information of the RBF kernel and its hyperparameters, you can look at:\n",
    "* Slides 33-34 of https://github.com/mlberkeley/Machine-Learning-Decal-Spring-2018/blob/master/Lecture%206/Lecture%206%20Slides.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=10, gamma=..., probability=True)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(data[['X1', 'X2']], data['y'])\n",
    "svc.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Probability'] = svc.predict_proba(data[['X1', 'X2']])[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
